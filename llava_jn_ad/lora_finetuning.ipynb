{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dudxE-qKj-6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import uuid\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = #path to xdata\n",
        "y_data = #path to ydata"
      ],
      "metadata": {
        "id": "TMtjnBjuK2Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target for stage 1 output\n",
        "\n",
        "target_sen = {'aluminum_can': 'tin can',\n",
        "              'paper_cup': 'paper cup',\n",
        "              'boxes':'cardboard box',\n",
        "              'soda_can':'plastic bottle',\n",
        "              'glass_bottle':'glass bottle'}"
      ],
      "metadata": {
        "id": "yIlJm4v9MVlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_json_data(x_data, y_data, output_folder, train_num, prompt):\n",
        "\n",
        "  id_list = []\n",
        "  path_list = []\n",
        "  target_sen_list = []\n",
        "\n",
        "\n",
        "  for i in range(x_data.shape[0]):\n",
        "\n",
        "    im = Image.fromarray(x_data[i])\n",
        "\n",
        "    im_id = str(uuid.uuid4())\n",
        "    im_path = os.path.join(output_folder, im_id + '.jpg')\n",
        "\n",
        "    id_list.append(im_id)\n",
        "    path_list.append(im_path)\n",
        "\n",
        "    im.save(im_path)\n",
        "\n",
        "    tar_sen = target_sen[y_data[i]]\n",
        "\n",
        "    target_sen_list.append(tar_sen)\n",
        "\n",
        "  json_df = pd.DataFrame({'id':id_list, 'path':path_list, 'target_sentence':target_sen_list})\n",
        "\n",
        "  train_idxs = random.randint(0, len(json_df-1), train_num)\n",
        "\n",
        "  train_df = json_df[df.index.isin(train_idxs)]\n",
        "  train_df = train_df.reset_index(drop=True)\n",
        "\n",
        "  val_df = json_df[~df.index.isin(train_idxs)]\n",
        "  val_df = val_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "  json_data_list = []\n",
        "\n",
        "  for idx in range(len(train_df)):\n",
        "\n",
        "    json_data = {\n",
        "        'id': train_df.iloc[idx]['id'],\n",
        "        'image' : train_df.iloc[idx]['path'],\n",
        "        'conversations': [\n",
        "            {\n",
        "                'from': 'human',\n",
        "                'value': prompt\n",
        "            },\n",
        "            {\n",
        "                'from': 'gpt',\n",
        "                'value': train_df.iloc[idx]['target_sentence']\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    json_data_list.append(json_data)\n",
        "\n",
        "    json_output_path = os.path.join(output_folder, 'json/train_dataset.json')\n",
        "    with open(json_output_path, 'w') as json_file:\n",
        "        json.dump(json_data_list, json_file, indent=4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K1cBbQcJLzBT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}